{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a8d7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]\n",
      "Python executable: c:\\Users\\Sarthak\\OneDrive\\Documents\\Desktop\\Python projects\\genai-workshop\\.venv\\Scripts\\python.exe\n",
      "‚úÖ Python version is compatible!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# TODO: Print the Python version using \n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# TODO: Print the Python executable path using \n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "version_info = sys.version_info\n",
    "if version_info.major == 3 and version_info.minor >= 10:\n",
    "    print(\"‚úÖ Python version is compatible!\")\n",
    "else:\n",
    "    print(\"‚ùå Python version is too old. Please upgrade to 3.10+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6566806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: <module 'torch.cuda' from 'c:\\\\Users\\\\Sarthak\\\\OneDrive\\\\Documents\\\\Desktop\\\\Python projects\\\\genai-workshop\\\\.venv\\\\Lib\\\\site-packages\\\\torch\\\\cuda\\\\__init__.py'>\n",
      "GPU device: <module 'torch.cuda' from 'c:\\\\Users\\\\Sarthak\\\\OneDrive\\\\Documents\\\\Desktop\\\\Python projects\\\\genai-workshop\\\\.venv\\\\Lib\\\\site-packages\\\\torch\\\\cuda\\\\__init__.py'>\n",
      "CUDA version: <module 'torch.version' from 'c:\\\\Users\\\\Sarthak\\\\OneDrive\\\\Documents\\\\Desktop\\\\Python projects\\\\genai-workshop\\\\.venv\\\\Lib\\\\site-packages\\\\torch\\\\version.py'>\n",
      "Number of GPUs: <module 'torch.cuda' from 'c:\\\\Users\\\\Sarthak\\\\OneDrive\\\\Documents\\\\Desktop\\\\Python projects\\\\genai-workshop\\\\.venv\\\\Lib\\\\site-packages\\\\torch\\\\cuda\\\\__init__.py'>\n",
      "\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# TODO: Check if CUDA is available\n",
    "cuda_available = torch.cuda  # Use  method\n",
    "\n",
    "print(f\"CUDA available: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    # TODO: Get GPU device name\n",
    "    gpu_name = torch.cuda  # Use torch.cuda method\n",
    "    print(f\"GPU device: {gpu_name}\")\n",
    "    \n",
    "    # TODO: Get CUDA version\n",
    "    cuda_version = torch.version  # Use torch.version attribute\n",
    "    print(f\"CUDA version: {cuda_version}\")\n",
    "    \n",
    "    # TODO: Get number of available GPUs\n",
    "    gpu_count = torch.cuda  # Use torch.cuda method\n",
    "    print(f\"Number of GPUs: {gpu_count}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU available - using CPU\")\n",
    "    print(\"üí° Consider using Google Colab for free GPU access\")\n",
    "\n",
    "# TODO: Set device for computations\n",
    "device = torch.device('cuda') if cuda_available else torch.device('cpu')  # torch.device\n",
    "print(f\"\\nUsing device: {device}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
